{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeavePOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import networkx as nx\n",
    "import math\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475837529743534588728"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./OTCNet.csv')\n",
    "\n",
    "N = 5\n",
    "\n",
    "X =  df\n",
    "#y =  df['rating']\n",
    "X = X.values\n",
    "#y = y.values\n",
    "\n",
    "lpo = LeavePOut(N)\n",
    "lpo.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_scores_bd(G):\n",
    "    bias = {}\n",
    "    deserve = {}\n",
    "    \n",
    "    nodes = G.nodes()\n",
    "    #print(nodes)\n",
    "    for node in nodes:\n",
    "        bias[node] = -1\n",
    "        try:\n",
    "            deserve[node] = G.in_degree(node, weight='weight')*1.0/G.in_degree(node)\n",
    "        except:\n",
    "            deserve[node] = 0\n",
    "    return bias, deserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bias_deserve(G):\n",
    "    bias, deserve = initialize_scores_bd(G)\n",
    "    \n",
    "    nodes = G.nodes()\n",
    "    iter = 0\n",
    "    while iter < 100:\n",
    "        d = 0\n",
    "        db = 0\n",
    "        \n",
    "        for node in nodes:\n",
    "            inedges = G.in_edges(node, data='weight')\n",
    "            #print(inedges)\n",
    "            d = 0\n",
    "            for edge in inedges:\n",
    "                Xkj = max(0, bias[node]*edge[2])\n",
    "                d += edge[2]*(1 - Xkj)\n",
    "            try:\n",
    "                dd += abs(d/len(inedges) - deserve[node])\n",
    "                deserve[node] = d/len(inedges)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        for node in nodes:\n",
    "            outedges = G.out_edges(node, data='weight')\n",
    "            b = 0\n",
    "            for edge in outedges: \n",
    "                b += (edge[2] - deserve[edge[1]])\n",
    "            try:\n",
    "                db += abs(b/(2*len(outedges)) - bias[node])\n",
    "                bias[node] = b/(2*len(outedges))\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        \n",
    "        if db < math.pow(10, -6):\n",
    "            break\n",
    "        #print('Differences in bias score score = %.2f' % db)\n",
    "        iter+=1\n",
    "    \n",
    "    return bias, deserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n"
     ]
    }
   ],
   "source": [
    "# only for first 20 iterations\n",
    "itr = 10\n",
    "bias = {}\n",
    "deserve = {}\n",
    "predicted = pd.DataFrame(np.random.randn(5, 1), columns=['rat'])\n",
    "test = pd.DataFrame(np.random.randn(5, 1), columns=['rat'])\n",
    "\n",
    "goodness_test = {}\n",
    "RMSE = 0\n",
    "PCC = 0\n",
    "for train_index, test_index in lpo.split(X):\n",
    "    if test_index[4] < (itr+N):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        G = nx.DiGraph()\n",
    "        test['rat'][0] = X_test[0][2]\n",
    "        test['rat'][1] = X_test[1][2]\n",
    "        test['rat'][2] = X_test[2][2]\n",
    "        test['rat'][3] = X_test[3][2]\n",
    "        test['rat'][4] = X_test[4][2]\n",
    "        for index in range(0, 35587):\n",
    "            G.add_edge(X_train[index][0], X_train[index][1], weight = float(X_train[index][2])) ## the weight should already be in the range of -1 to 1\n",
    "        try:\n",
    "            bias, deserve = compute_bias_deserve(G)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            predicted['rat'][0] = deserve[X_test[0][1]]\n",
    "        except:\n",
    "            predicted['rat'][0] = 0\n",
    "            continue\n",
    "        try:\n",
    "            predicted['rat'][1] = deserve[X_test[1][1]]\n",
    "        except:\n",
    "            predicted['rat'][1] = 0\n",
    "            continue\n",
    "        try:\n",
    "            predicted['rat'][2] = deserve[X_test[2][1]]\n",
    "        except:\n",
    "            predicted['rat'][2] = 0\n",
    "            continue\n",
    "        try:\n",
    "            predicted['rat'][3] = deserve[X_test[3][1]]\n",
    "        except:\n",
    "            predicted['rat'][3] = 0\n",
    "            continue\n",
    "        try:\n",
    "            predicted['rat'][4] = deserve[X_test[4][1]]\n",
    "        except:\n",
    "            predicted['rat'][4] = 0\n",
    "            continue\n",
    "    else:\n",
    "        break\n",
    "    RMSE += math.sqrt(mean_squared_error(test['rat'], predicted['rat']))\n",
    "    PCC += np.corrcoef(test['rat'], predicted['rat'])\n",
    "    print('iteration', test_index[4] - N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3986889987620701"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMES_bd_leaveNout = RMSE/itr\n",
    "RMES_bd_leaveNout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.34813613],\n",
       "       [-0.34813613,  1.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCC_bd_leaveNout = PCC/itr\n",
    "PCC_bd_leaveNout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
