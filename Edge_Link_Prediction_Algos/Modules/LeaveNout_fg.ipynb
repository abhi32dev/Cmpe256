{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeavePOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import networkx as nx\n",
    "import math\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475837529743534588728"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./OTCNet.csv')\n",
    "\n",
    "N = 5\n",
    "\n",
    "X =  df\n",
    "#y =  df['rating']\n",
    "X = X.values\n",
    "#y = y.values\n",
    "\n",
    "lpo = LeavePOut(N)\n",
    "lpo.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_scores(G):\n",
    "    fairness = {}\n",
    "    goodness = {}\n",
    "    \n",
    "    nodes = G.nodes()\n",
    "    #print(nodes)\n",
    "    for node in nodes:\n",
    "        fairness[node] = 1\n",
    "        try:\n",
    "            goodness[node] = G.in_degree(node, weight='weight')*1.0/G.in_degree(node)\n",
    "        except:\n",
    "            goodness[node] = 0\n",
    "    return fairness, goodness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fairness_goodness(G):\n",
    "    fairness, goodness = initialize_scores(G)\n",
    "    \n",
    "    nodes = G.nodes()\n",
    "    iter = 0\n",
    "    while iter < 100:\n",
    "        df = 0\n",
    "        dg = 0\n",
    "        for node in nodes:\n",
    "            inedges = G.in_edges(node, data='weight')\n",
    "            #print(inedges)\n",
    "            g = 0\n",
    "            for edge in inedges:\n",
    "                g += fairness[edge[0]]*edge[2]\n",
    "\n",
    "            try:\n",
    "                dg += abs(g/len(inedges) - goodness[node])\n",
    "                goodness[node] = g/len(inedges)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        for node in nodes:\n",
    "            outedges = G.out_edges(node, data='weight')\n",
    "            f = 0\n",
    "            for edge in outedges:\n",
    "                f += 1.0 - abs(edge[2] - goodness[edge[1]])/2.0\n",
    "            try:\n",
    "                df += abs(f/len(outedges) - fairness[node])\n",
    "                fairness[node] = f/len(outedges)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if df < math.pow(10, -6) and dg < math.pow(10, -6):\n",
    "            break\n",
    "        iter+=1\n",
    "    \n",
    "    return fairness, goodness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n"
     ]
    }
   ],
   "source": [
    "# only for first 20 iterations\n",
    "itr = 10\n",
    "fairness = {}\n",
    "goodness = {}\n",
    "predicted = pd.DataFrame(np.random.randn(5, 1), columns=['rat'])\n",
    "test = pd.DataFrame(np.random.randn(5, 1), columns=['rat'])\n",
    "goodness_test = {}\n",
    "RMSE = 0\n",
    "PCC = 0\n",
    "for train_index, test_index in lpo.split(X):\n",
    "    if test_index[4] < (itr+N):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        G = nx.DiGraph()\n",
    "        test['rat'][0] = X_test[0][2]\n",
    "        test['rat'][1] = X_test[1][2]\n",
    "        test['rat'][2] = X_test[2][2]\n",
    "        test['rat'][3] = X_test[3][2]\n",
    "        test['rat'][4] = X_test[4][2]\n",
    "        for index in range(0, 35587):\n",
    "            G.add_edge(X_train[index][0], X_train[index][1], weight = float(X_train[index][2])) ## the weight should already be in the range of -1 to 1\n",
    "        try:\n",
    "            fairness, goodness = compute_fairness_goodness(G)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            predicted['rat'][0] = fairness[X_test[0][0]]*goodness[X_test[0][1]]\n",
    "        except:\n",
    "            predicted['rat'][0] = 0\n",
    "            continue\n",
    "        try:\n",
    "            predicted['rat'][1] = fairness[X_test[1][0]]*goodness[X_test[1][1]]\n",
    "        except:\n",
    "            predicted['rat'][1] = 0\n",
    "            continue\n",
    "        try:\n",
    "            predicted['rat'][2] = fairness[X_test[2][0]]*goodness[X_test[2][1]]\n",
    "        except:\n",
    "            predicted['rat'][2] = 0\n",
    "            continue\n",
    "        try:\n",
    "            predicted['rat'][3] = fairness[X_test[3][0]]*goodness[X_test[3][1]]\n",
    "        except:\n",
    "            predicted['rat'][3] = 0\n",
    "            continue\n",
    "        try:\n",
    "            predicted['rat'][4] = fairness[X_test[4][0]]*goodness[X_test[4][1]]\n",
    "        except:\n",
    "            predicted['rat'][4] = 0\n",
    "            continue\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    RMSE += math.sqrt(mean_squared_error(test['rat'], predicted['rat']))\n",
    "    PCC += np.corrcoef(test['rat'], predicted['rat'])\n",
    "    print('iteration', test_index[4] - N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.406733391531918"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMES_fg_leaveNout = RMSE/itr\n",
    "RMES_fg_leaveNout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.37802359],\n",
       "       [-0.37802359,  1.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCC_fg_leaveNout = PCC/itr\n",
    "PCC_fg_leaveNout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
